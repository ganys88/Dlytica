# -*- coding: utf-8 -*-
"""Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YX9FO7gO3yF8wd9IgD2LvOt10Qyu9zrM
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

url = 'https://books.toscrape.com/'                 #import url
response = requests.get(url, timeout=30)            #makes request to url and store in response variable

soup = BeautifulSoup(response.text, 'html.parser')

import numpy as np
response.encoding = 'utf-8'

books = []                                                       # create an empty list

for art in soup.select('article.product_pod'):                   # 'art' is variable for article
    title = art.h3.a['title']
    price_text = art.select_one('p.price_color').text.strip()
    price = float(price_text.replace('£', '').replace('Â', ''))  # Replace both '£' and 'Â' before converting to float
    rating_class = art.select_one('p.star-rating')['class'][1]
    stars_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
    stars = stars_map.get(rating_class, 0)
    books.append({'title': title, 'price': price, 'stars':stars}) # append (this method) adds the created dictionary (title,price,stars) to list (book[]).

print(books)

# scrape multiple pages
all_books = []                      # create an empty list
for page in range(1,11):
  urls = f'https://books.toscrape.com/catalogue/page-{page}.html'
  print(urls)

all_books = []                      # create an empty list
for page in range(1,10):
  urls = f'https://books.toscrape.com/catalogue/page-{page}.html'
  print(urls)

  resp = requests.get(urls, timeout=30)
  resp.encoding = 'utf-8'
  soup = BeautifulSoup(resp.text, 'html.parser')

  for art in soup.select('article.product_pod'):
    title = art.h3.a['title']
    price_text = art.select_one('p.price_color').text
    price = float(price_text.strip('£'))
    rating_class = art.p['class'][1]
    rating = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}[rating_class]
    stars = stars_map.get(rating_class, 0)
    all_books.append({'title': title, 'price': price, 'stars': stars})

# create dataframe : convert the list of book data into a pandas dataframe

import pandas as pd

df = pd.DataFrame(all_books)

print(df)

# for reference only (self)
book_df = pd.DataFrame(books)  # this is just for page one
print(book_df)

base_url ='https://books.toscrape.com/catalogue/page-1.html'

all_quotes = []   # create an empty list

# loop over pages
for page in range(1,11):
  url = base_url.replace('1', str(page))
  print(url)

  resp = requests.get(url, timeout=30)
  resp.encoding = 'utf-8'
  soup = BeautifulSoup(resp.text, 'html.parser')

  for quote_block in soup.select('div.quote'):
    quote = quote_block.select_one('span.text').text
    author = quote_block.select_one('small.author').text
    author_link = base_url + quote_block.find('a')['href']
    author_resp = requests.get(author_link, timeout=30)           # scrape author details
    author_soup = BeautifulSoup(author_resp.text, 'html.parser')
    birth_date = author_soup.select_one('span.author-born-date').text
    birth_location = author_soup.select_one('span.author-born-location').text

    all_quotes.append({'quote': quote, 'author': author, 'birth_date': birth_date, 'birth_location': birth_location})
    #append dictionary to the list all_quotes

df_all_quotes = pd.DataFrame(all_quotes)
print(df_all_quotes)