# -*- coding: utf-8 -*-
"""API_Scraping_Visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZyTLQsaZbqbHzRt2uy9ESDHfMdZb2LFE
"""

! pip install requests pandas numpy matplotlib seaborn beautifulsoup4 lxml

# step 1
# fetching data from API

import requests
import pandas as pd

URL = "https://api.spacexdata.com/v4/launches"
resp = requests.get(URL, timeout = 30)                            # makes a request to a website and store the response in 'resp' variable
data = resp.json()
pd.json_normalize(data)

launches = pd.json_normalize(data)      # store data into 'launches' variable # assign a variable for data
launches.head()

len(launches)

launches.columns

# step 2
# clean the data and feature engineering

launches = launches[['name','date_utc','success','flight_number']].copy()
launches['date_utc'] = pd.to_datetime(launches['date_utc'], errors = 'coerce')
launches['year'] = launches['date_utc'].dt.year
launches['success_bool'] = launches['success'].fillna(False).astype(bool)

print(launches)

# step 3
# summarize the data for insights

import numpy as np

per_year = launches.groupby('year').agg(
    launches = ('flight_number', 'count'),
    successes = ('success_bool', 'sum'),
    success_rate = ('success_bool', 'mean')
).reset_index()

per_year['success_rate'] = per_year['successes']/per_year['launches']
print(per_year)

# step 4
# visualization

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure()  # this creates a new blank canvas
sns.barplot(x = 'year', y = 'launches', data = per_year)
plt.xticks(rotation = 90)   # without this the xticks('x labels') with overlap with eachother.
plt.title('Launches per year')
plt.show()

# basic syntax for visualization
plt.figure()
plt.show()

# you put everything inbetween
# like data, xlabel, ylabel, title, xticks('xlabels' orientation) etc

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure()

sns.lineplot(x = 'year', y = 'success_rate', data=per_year, marker='o')
plt.xticks(rotation = 90)
plt.title('Success rate per year')
plt.ylim(0,1)     # this limit the start point from 0 to 1.
plt.ylabel('Success rate')

plt.show()

"""=================================================

2nd hands on : webscraping to visualization
"""

# step 1 : scraping the website
 import requests
 from bs4 import BeautifulSoup

 URL = 'https://books.toscrape.com/catalogue/page-1.html'
 resp = requests.get(URL, timeout=30)
                                                                   # to know what kinda parser we need to use just
                                                                    # print(resp.text) # it will give what kind of text does the url have
 soup = BeautifulSoup(resp.text, 'html.parser')

# books = []                                      # this creates a empty list that we gonna fill with the component we extract from the url.
# for art in soup.select('article.product_pod'):
#     title = art.h3.a['title']                    # this is from html
#     books.append(title)                         # this line appends or adds title to empty list that we created.

# print(books)

import requests
from bs4 import BeautifulSoup

url = 'https://books.toscrape.com/catalogue/page-1.html'
resp = requests.get(url, timeout=30)

resp.encoding = 'utf-8'

soup = BeautifulSoup(resp.text, 'html.parser')

books = []
for art in soup.select('article.product_pod'):
    title = art.h3.a['title']
    price_text = art.select_one('p.price_color').text.strip()
    price = float(price_text.replace('£', ''))
    rating_class = art.p['class'][1]
    stars_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
    stars = stars_map[rating_class]
    books.append({'title':title, 'price':price, 'stars':stars})


print(books)

# step 2: scrape multiple pages
all_books = []
for page in range(1, 10):
    urls = f'https://books.toscrape.com/catalogue/page-{page}.html'
    print(urls)
    resp = requests.get(urls, timeout=30)
    resp.encoding = 'utf-8'
    soup = BeautifulSoup(resp.text, 'html.parser')

    for art in soup.select('article.product_pod'):
      title = art.h3.a['title']
      price_text = art.select_one('p.price_color').text.strip()
      price = float(price_text.replace('£', ''))
      rating_class = art.p['class'][1]
      stars_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
      stars = stars_map[rating_class]
      all_books.append({'title':title, 'price':price, 'stars':stars})

# step 3: cleaning and standardizing
import pandas as pd
books_df = pd.DataFrame(all_books)

print(books_df)

# step 4: visualization
import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=books_df, x='stars', y='price')
plt.title('Price per star rating')
plt.show()